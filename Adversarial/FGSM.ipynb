{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据条目数： 34394\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 1. 读取数据\n",
    "###########################\n",
    "input_csv = \"NSL-KDD-Test.csv\"\n",
    "output_csv = \"NSL-KDD-FGSM-Adversarial.csv\"\n",
    "\n",
    "df = pd.read_csv(input_csv)\n",
    "print(\"原始数据条目数：\", len(df))\n",
    "\n",
    "# 假设最后一列是 class，其他列都是特征\n",
    "feature_cols = df.columns[:-1]  # 除最后一列外\n",
    "label_col = df.columns[-1]      # 最后一列\n",
    "\n",
    "# 将特征和标签分开\n",
    "X = df[feature_cols].copy()\n",
    "y = df[label_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# 2. 汇总数值特征与离散特征\n",
    "###########################\n",
    "# 在实际中可以根据 dtype，或手动指定\n",
    "numeric_cols = ['duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent']\n",
    "categorical_cols = [c for c in feature_cols if c not in numeric_cols]\n",
    "\n",
    "# 处理数值特征\n",
    "X_numeric = X[numeric_cols]\n",
    "\n",
    "# 处理离散特征：将离散特征列转换为数值\n",
    "X_categorical = X[categorical_cols]\n",
    "\n",
    "# 将离散特征转换为数值（标签编码）\n",
    "for col in X_categorical.columns:\n",
    "    X_categorical.loc[:, col] = pd.factorize(X_categorical[col])[0]  # 使用 .loc 赋值\n",
    "\n",
    "# 标签映射\n",
    "label_map = {}\n",
    "current_label_id = 0\n",
    "for label_val in y.unique():\n",
    "    label_map[label_val] = current_label_id\n",
    "    current_label_id += 1\n",
    "\n",
    "y_numerical = y.map(label_map)  # 将 y 转为 0, 1, 2,... 之类的int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# 3. 构造模型（数值特征与离散特征）\n",
    "###########################\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, numeric_input_dim, categorical_input_dim, embedding_dim=10, hidden_dim=32, output_dim=2):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        \n",
    "        # 数值特征的全连接层\n",
    "        self.fc1_numeric = nn.Linear(numeric_input_dim, hidden_dim)\n",
    "        \n",
    "        # 离散特征的嵌入层\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(len(X[c].unique()), embedding_dim) for c in categorical_cols\n",
    "        ])\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim + len(categorical_cols) * embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, numeric_input, categorical_input):\n",
    "        # 数值特征处理\n",
    "        numeric_out = self.relu(self.fc1_numeric(numeric_input))\n",
    "        \n",
    "        # 离散特征处理\n",
    "        embedded = [embedding(categorical_input[:, i]) for i, embedding in enumerate(self.embeddings)]\n",
    "        categorical_out = torch.cat(embedded, dim=1)\n",
    "        \n",
    "        # 合并数值特征与离散特征\n",
    "        x = torch.cat([numeric_out, categorical_out], dim=1)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "# 模型初始化\n",
    "model = SimpleNet(numeric_input_dim=len(numeric_cols), categorical_input_dim=len(categorical_cols), embedding_dim=10)\n",
    "model.eval()  # 这里仅为示例；真实要加载训练好的模型参数\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epsilon = 0.1  # 扰动系数，可自行调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# 4. FGSM 函数（对数值特征和离散特征做扰动）\n",
    "###########################\n",
    "def fgsm_attack(model, loss_fn, numeric_data, categorical_data, label, epsilon):\n",
    "    \"\"\"\n",
    "    对数值和离散特征做扰动\n",
    "    numeric_data: 数值特征 tensor\n",
    "    categorical_data: 离散特征 tensor\n",
    "    label: [1] 的tensor, 真实或目标标签\n",
    "    \"\"\"\n",
    "    # 前向传播\n",
    "    output = model(numeric_data, categorical_data)\n",
    "    loss = loss_fn(output, label)\n",
    "    \n",
    "    # 反向传播\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # data.grad 即为 dLoss/dData\n",
    "    numeric_data_grad = numeric_data.grad.data\n",
    "    categorical_data_grad = []\n",
    "    \n",
    "    # 对离散特征进行扰动\n",
    "    for emb, cat_data in zip(model.embeddings, categorical_data.split(1, dim=1)):\n",
    "        cat_data.requires_grad = True\n",
    "        cat_data_grad = torch.autograd.grad(loss, cat_data)[0]\n",
    "        categorical_data_grad.append(cat_data_grad)\n",
    "\n",
    "    # 对数值特征和离散特征分别做扰动\n",
    "    numeric_perturbed = numeric_data + epsilon * numeric_data_grad.sign()\n",
    "    categorical_perturbed = torch.cat([cat_data + epsilon * cat_grad.sign() for cat_data, cat_grad in zip(categorical_data.split(1, dim=1), categorical_data_grad)], dim=1)\n",
    "\n",
    "    return numeric_perturbed, categorical_perturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating adversarial samples:   0%|          | 0/34394 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m x_categorical\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# 离散特征不直接计算梯度，通过嵌入层进行\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 执行 FGSM\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m x_numeric_adv, x_categorical_adv \u001b[38;5;241m=\u001b[39m \u001b[43mfgsm_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# 将扰动后的数值列更新回\u001b[39;00m\n\u001b[0;32m     33\u001b[0m X_numeric_adv\u001b[38;5;241m.\u001b[39miloc[idx] \u001b[38;5;241m=\u001b[39m x_numeric_adv\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[87], line 25\u001b[0m, in \u001b[0;36mfgsm_attack\u001b[1;34m(model, loss_fn, numeric_data, categorical_data, label, epsilon)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 对离散特征进行扰动\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m emb, cat_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(model\u001b[38;5;241m.\u001b[39membeddings, categorical_data\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mcat_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     cat_data_grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(loss, cat_data)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m     categorical_data_grad\u001b[38;5;241m.\u001b[39mappend(cat_data_grad)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 5. 对每一行做对抗扰动（数值特征和分类特征都做扰动）\n",
    "###########################\n",
    "X_numeric_adv = X_numeric.astype('float64').copy()  # 确保是 float 类型\n",
    "\n",
    "# 对离散特征进行编码（确保它们是数值型）\n",
    "X_categorical_encoded = X_categorical.apply(lambda col: pd.factorize(col)[0])\n",
    "\n",
    "# 将离散特征转换为 Tensor\n",
    "X_categorical_tensor = torch.tensor(X_categorical_encoded.values, dtype=torch.long)\n",
    "\n",
    "# 创建进度条\n",
    "for idx in tqdm(range(len(X_numeric)), desc=\"Generating adversarial samples\"):\n",
    "    # 1) 数值特征转 tensor\n",
    "    row_values_numeric = X_numeric.iloc[idx].values.astype('float32')  # [input_dim, ]\n",
    "    x_numeric = torch.tensor(row_values_numeric).unsqueeze(0)  # [1, input_dim]\n",
    "    \n",
    "    # 2) 离散特征转 tensor\n",
    "    x_categorical = X_categorical_tensor[idx].unsqueeze(0)  # [1, num_categorical]\n",
    "    \n",
    "    # 对应标签\n",
    "    label_val = y_numerical.iloc[idx]\n",
    "    y_t = torch.tensor([label_val], dtype=torch.long)\n",
    "    \n",
    "    # 准备对 x 求梯度\n",
    "    x_numeric.requires_grad = True\n",
    "    x_categorical.requires_grad = False  # 离散特征不直接计算梯度，通过嵌入层进行\n",
    "    \n",
    "    # 执行 FGSM\n",
    "    x_numeric_adv, x_categorical_adv = fgsm_attack(model, loss_fn, x_numeric, x_categorical, y_t, epsilon)\n",
    "    \n",
    "    # 将扰动后的数值列更新回\n",
    "    X_numeric_adv.iloc[idx] = x_numeric_adv.detach().numpy().squeeze(0)\n",
    "\n",
    "    # 对离散特征的处理：利用嵌入层并映射回类别\n",
    "    # 让嵌入向量的梯度反向传播\n",
    "    for i, emb in enumerate(model.embeddings):\n",
    "        cat_data = x_categorical[:, i]  # 取当前类别的嵌入数据\n",
    "        cat_data.requires_grad = True  # 让离散特征的嵌入层计算梯度\n",
    "        emb_out = emb(cat_data)  # 获取嵌入向量\n",
    "        \n",
    "        # 使用 sign() 来做扰动\n",
    "        emb_out_grad = emb_out.grad.data.sign() * epsilon\n",
    "        x_categorical_adv[:, i] = emb_out + emb_out_grad\n",
    "    \n",
    "    # 将扰动后的离散特征映射回原类别（可以选择最近的嵌入）\n",
    "    for i, col in enumerate(categorical_cols):\n",
    "        max_idx = x_categorical_adv[0, i].argmax().item()\n",
    "        X_categorical[col].iloc[idx] = X_categorical[col].unique()[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对抗样本已保存到 NSL-KDD-FGSM-Adversarial.csv\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# 6. 合并离散特征 + 对抗后数值特征 + 标签\n",
    "###########################\n",
    "# 离散特征保持原样\n",
    "X_adv = pd.concat([X_categorical, X_numeric_adv], axis=1)[feature_cols]\n",
    "\n",
    "# 标签列保持原来的值\n",
    "df_adv = pd.DataFrame(X_adv)\n",
    "df_adv[label_col] = y  # class 列保持不变（或者写成 y.map(...) 也行）\n",
    "\n",
    "# 保存\n",
    "df_adv.to_csv(output_csv, index=False)\n",
    "print(f\"对抗样本已保存到 {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
